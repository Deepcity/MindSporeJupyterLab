# 安装 mindformers 包
get_ipython().getoutput("pip install -i https://pypi.mirrors.ustc.edu.cn/simple mindformers==1.0.1")


# 若出现ValueError: Failed to read the checkpoint file . May not have permission to read it, please check the correct of the file. 请将下面注释放开
#!rm -rf checkpoint_download/vit/ 
from mindformers.pipeline import pipeline
from mindformers.tools.image_tools import load_image
from PIL import Image
import matplotlib.pyplot as plt

pipeline_task = pipeline("image_classification", model="vit_base_p16")


from PIL import Image
import matplotlib.pyplot as plt

# 可以使用 images 目录下的图片进行识别 ("images/daisy.jpg" or "images/strawberry.jpeg")
test_png = "images/daisy.jpg"
picture = Image.open(test_png)
plt.figure('image')
plt.imshow(picture)
plt.show()


img = load_image(test_png)
pipeline_result = pipeline_task(img, top_k=3)
pipeline_result


# pipeline接口开启快速推理
from mindformers.pipeline import TokenClassificationPipeline
from mindformers import AutoTokenizer, BertForTokenClassification, AutoConfig
from mindformers.dataset.labels import cluener_labels

id2label = {label_id: label for label_id, label in enumerate(cluener_labels)}

tokenizer = AutoTokenizer.from_pretrained(
    "tokcls_bert_base_chinese_cluener",
)
tokcls_cluener_config = AutoConfig.from_pretrained(
    "tokcls_bert_base_chinese_cluener",
)

# This is a known issue, you need to specify batch size equal to 1 when creating bert model.
tokcls_cluener_config.batch_size = 1

model = BertForTokenClassification(tokcls_cluener_config)
tokcls_pipeline = TokenClassificationPipeline(task='token_classification',
                                              model=model,
                                              id2label=id2label,
                                              tokenizer=tokenizer,
                                              max_length=model.config.seq_length,
                                              padding="max_length")


input_data = ["小明作为开发人员去北京参加华为开发者大会。"]
results = tokcls_pipeline(input_data)
print(results)


from download import download

url = (
    "https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/"
    "notebook/datasets/MNIST_Data.zip"
)
path = download(url, "./", kind="zip", replace=True)


from mindvision.classification.models import lenet

network = lenet(num_classes=10, pretrained=False)


# 超参设置
learning_rate = 0.01
momentum = 0.9
batch_size = 32
num_epochs = 5
epoch_size = 10


import mindspore.nn as nn

# 定义损失函数
net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')

# 定义优化器函数
net_opt = nn.Momentum(network.trainable_params(), learning_rate=learning_rate, momentum=momentum)


from mindspore.train import Model
from mindvision.classification.dataset import Mnist
from mindspore.train.callback import ModelCheckpoint, CheckpointConfig
from mindvision.engine.callback import LossMonitor

data_url = "./MNIST_Data"
output_path = "./lenet"

# 初始化模型参数
model = Model(network, loss_fn=net_loss, optimizer=net_opt, metrics={'accuracy'})

def train():
    # 定义训练数据集
    download_train = Mnist(
        path=data_url,
        split="train",
        batch_size=batch_size,
        repeat_num=1,
        shuffle=True,
        resize=32,
        download=True,
    )
    dataset_train = download_train.run()
    
    # 设置模型保存参数，模型训练保存参数的step为1875
    config_ck = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=10)
    
    # 应用模型保存参数
    ckpoint = ModelCheckpoint(prefix="lenet", directory=output_path, config=config_ck)
    
    # 训练网络模型，并保存为lenet-1_1875.ckpt文件
    model.train(epoch_size, dataset_train, callbacks=[ckpoint, LossMonitor(0.01, 1875)])

# 执行训练
train()


def evaluate():
    # 定义训练数据集
    download_test = Mnist(
        path=data_url,
        split="test",
        batch_size=batch_size,
        repeat_num=1,
        shuffle=True,
        resize=32,
        download=True,
    )
    dataset_test = download_test.run()
    acc = model.eval(dataset_test)
    print("{}".format(acc))
    
evaluate()


import numpy as np
from mindspore import Tensor
import matplotlib.pyplot as plt

mnist = Mnist(data_url, split="train", batch_size=6, resize=32)
dataset_infer = mnist.run()
ds_test = dataset_infer.create_dict_iterator()
data = next(ds_test)
images = data["image"].asnumpy()
labels = data["label"].asnumpy()

plt.figure()
for i in range(1, 7):
    plt.subplot(2, 3, i)
    plt.imshow(images[i-1][0], interpolation="None", cmap="gray")
plt.show()

# 使用函数model.predict预测image对应分类
output = model.predict(Tensor(data['image']))
predicted = np.argmax(output.asnumpy(), axis=1)

# 输出预测分类与实际分类
print(f'Predicted: "{predicted}", Actual: "{labels}"')


import cv2
import gradio as gr
import numpy as np
from mindspore import Tensor, load_checkpoint, load_param_into_net
from mindspore.nn import Softmax
from mindspore.train import Model
from mindvision.classification.models import lenet

NUM_CLASS = 10
ckpt_path = "./lenet/lenet-1_1875.ckpt"

# 加载网路
# 将模型参数存入parameter的字典中
param_dict = load_checkpoint(ckpt_path)

# 重新定义一个LeNet神经网络,注意输入是32*32，loss采用的是SoftmaxCE
network = lenet(num_classes=NUM_CLASS, pretrained=False)

# 将参数加载到网络中
load_param_into_net(network, param_dict)
model = Model(network)

def predict_digit(img):
    # print('img['background'] 的形状: ', img['background'].shape)
    # 处理图片,转化为 N，C，H, W
    img = cv2.resize(img['background'],dsize=(32,32))
    # print('resize 后的形状: ', img.shape)
    # 四通道抽成单通道
    channels=cv2.split(img)
    img = channels[0]
    # print('channels[0] 的形状: ', img.shape)
    img = img.astype(np.float32)
    img = img / 255
    img = img.reshape((1, 1, 32, 32))

    # 预测
    predict_score = model.predict(Tensor(img)).reshape(-1)
    predict_probability = Softmax()(predict_score)

    return {str(i): predict_probability[i].asnumpy().item() for i in range(NUM_CLASS)}

# gradio 的使用如下，目前在线编程环境暂不支持打开 gradio,感兴趣的同学可以下载文件，打开注释，在本地运行。
# gr.Interface(
#     fn=predict_digit,
#     inputs="sketchpad",
#     outputs=gr.Label(num_top_classes=NUM_CLASS, label="预测类别"),
#     live=False,
#     css=".footer {display:none !important}",
#     title="0-9数字画板",
#     description="画0-9数字",
# ).launch(share=False)
